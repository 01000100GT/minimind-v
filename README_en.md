<div align="center">

![logo](./images/logo-minimind-v.png)

</div>


<div align="center">

![visitors](https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind-v)
[![GitHub Repo stars](https://img.shields.io/github/stars/jingyaogong/minimind-v?style=social)](https://github.com/jingyaogong/minimind-v/stargazers)
[![GitHub Code License](https://img.shields.io/github/license/jingyaogong/minimind-v?v=1)](LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/jingyaogong/minimind-v)](https://github.com/jingyaogong/minimind-v/commits/master)
[![GitHub pull request](https://img.shields.io/badge/PRs-welcome-blue)](https://github.com/jingyaogong/minimind-v/pulls)

</div>


<div align="center">
  <h3>"The Greatest Path is the Simplest"</h3>
</div>

<div align="center">

[ä¸­æ–‡](./README.md) | English

</div>


ðŸ‘‰Train a visual multimodal VLM with a small number of parameters from scratch

ðŸŽ‰Expected to be open sourced within 2024, we are working tirelessly on coding and training!

# License

This repository is licensed under the [Apache-2.0 License](LICENSE).

